{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA2SKGChMP3m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import gradio as gr\n",
        "\n",
        "DATA_PATH = \"/content/cleaned_dataset.xlsx\"   # change if needed\n",
        "MODEL_QUALITY_PATH = \"model_quality.pkl\"\n",
        "MODEL_POROSITY_PATH = \"model_porosity.pkl\"\n",
        "SCALER_PATH = \"scaler.pkl\"\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def load_data(path):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Dataset not found at: {path}\")\n",
        "    df = pd.read_excel(path)\n",
        "    required = {\"Build_Quality\", \"Porosity\"}\n",
        "    if not required.issubset(df.columns):\n",
        "        raise ValueError(f\"Dataset must contain columns: {required}. Found: {list(df.columns)}\")\n",
        "    X = df.drop(columns=[\"Build_Quality\", \"Porosity\"])\n",
        "    y_quality = df[\"Build_Quality\"]\n",
        "    y_porosity = df[\"Porosity\"]\n",
        "    return X, y_quality, y_porosity, df\n",
        "\n",
        "def train_or_load_models(X, yq, yp):\n",
        "    # If model files exist, load them\n",
        "    if os.path.exists(MODEL_QUALITY_PATH) and os.path.exists(MODEL_POROSITY_PATH) and os.path.exists(SCALER_PATH):\n",
        "        print(\"Loading saved models and scaler...\")\n",
        "        model_q = joblib.load(MODEL_QUALITY_PATH)\n",
        "        model_p = joblib.load(MODEL_POROSITY_PATH)\n",
        "        scaler = joblib.load(SCALER_PATH)\n",
        "        # We won't recompute performance here (unless you want to)\n",
        "        performance = None\n",
        "        return model_q, model_p, scaler, performance\n",
        "\n",
        "    # Else, train fresh models and save them.\n",
        "    print(\"Training models (no saved models found)...\")\n",
        "    X_train, X_test, yq_train, yq_test, yp_train, yp_test = train_test_split(\n",
        "        X, yq, yp, test_size=0.2, random_state=RANDOM_STATE, stratify=yq if len(np.unique(yq))>1 else None\n",
        "    )\n",
        "    scaler = StandardScaler()\n",
        "    X_train_s = scaler.fit_transform(X_train)\n",
        "    X_test_s = scaler.transform(X_test)\n",
        "\n",
        "    model_q = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
        "    model_q.fit(X_train_s, yq_train)\n",
        "\n",
        "    model_p = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
        "    model_p.fit(X_train_s, yp_train)\n",
        "\n",
        "    # Evaluate\n",
        "    yq_pred = model_q.predict(X_test_s)\n",
        "    yp_pred = model_p.predict(X_test_s)\n",
        "\n",
        "    acc_q = accuracy_score(yq_test, yq_pred)\n",
        "    acc_p = accuracy_score(yp_test, yp_pred)\n",
        "    cr_q = classification_report(yq_test, yq_pred, zero_division=0)\n",
        "    cr_p = classification_report(yp_test, yp_pred, zero_division=0)\n",
        "\n",
        "    performance = {\n",
        "        \"acc_quality\": acc_q,\n",
        "        \"acc_porosity\": acc_p,\n",
        "        \"report_quality\": cr_q,\n",
        "        \"report_porosity\": cr_p\n",
        "    }\n",
        "\n",
        "    # Save for reuse\n",
        "    joblib.dump(model_q, MODEL_QUALITY_PATH)\n",
        "    joblib.dump(model_p, MODEL_POROSITY_PATH)\n",
        "    joblib.dump(scaler, SCALER_PATH)\n",
        "    print(\"Models and scaler saved.\")\n",
        "\n",
        "    return model_q, model_p, scaler, performance\n",
        "\n",
        "# ---------- Prepare data & models ----------\n",
        "X, y_quality, y_porosity, df_full = load_data(DATA_PATH)\n",
        "\n",
        "# compute input ranges for UI\n",
        "input_ranges = {}\n",
        "for col in X.columns:\n",
        "    col_min = float(X[col].min())\n",
        "    col_max = float(X[col].max())\n",
        "    input_ranges[col] = (col_min, col_max)\n",
        "\n",
        "model_quality, model_porosity, scaler, performance = train_or_load_models(X, y_quality, y_porosity)\n",
        "\n",
        "# build a human-readable performance summary string (if available)\n",
        "if performance:\n",
        "    perf_text = (\n",
        "        f\"**Model Performance (test set)**\\n\\n\"\n",
        "        f\"- Build Quality Accuracy: {performance['acc_quality']:.4f}\\n\"\n",
        "        f\"- Porosity Accuracy: {performance['acc_porosity']:.4f}\\n\\n\"\n",
        "        f\"---\\n\\n\"\n",
        "        f\"**Build Quality classification report**\\n\\n```\\n{performance['report_quality']}\\n```\\n\"\n",
        "        f\"**Porosity classification report**\\n\\n```\\n{performance['report_porosity']}\\n```\\n\"\n",
        "        f\"---\\n\\n\"\n",
        "        f\"_Models saved to {MODEL_QUALITY_PATH}, {MODEL_POROSITY_PATH}, scaler saved to {SCALER_PATH}_\"\n",
        "    )\n",
        "else:\n",
        "    perf_text = (\n",
        "        \"_Loaded pre-saved models. If you want fresh training, delete the model .pkl files and rerun._\"\n",
        "    )\n",
        "\n",
        "# ---------- Prediction function ----------\n",
        "def predict_properties(*features):\n",
        "    # features come in same order as X.columns\n",
        "    arr = np.array([features], dtype=float)\n",
        "    try:\n",
        "        arr_s = scaler.transform(arr)\n",
        "    except Exception as e:\n",
        "        return (\"Error: scaler.transform failed. Check inputs.\", str(e), {}, {}, perf_text)\n",
        "\n",
        "    # predictions\n",
        "    pred_q = model_quality.predict(arr_s)[0]\n",
        "    pred_p = model_porosity.predict(arr_s)[0]\n",
        "\n",
        "    # probabilities (as dicts for gr.Label)\n",
        "    try:\n",
        "        probs_q = model_quality.predict_proba(arr_s)[0]\n",
        "        classes_q = model_quality.classes_\n",
        "        probs_q_dict = {str(cl): float(np.round(p, 4)) for cl, p in zip(classes_q, probs_q)}\n",
        "    except Exception:\n",
        "        probs_q_dict = {\"error\": 0.0}\n",
        "\n",
        "    try:\n",
        "        probs_p = model_porosity.predict_proba(arr_s)[0]\n",
        "        classes_p = model_porosity.classes_\n",
        "        probs_p_dict = {str(cl): float(np.round(p, 4)) for cl, p in zip(classes_p, probs_p)}\n",
        "    except Exception:\n",
        "        probs_p_dict = {\"error\": 0.0}\n",
        "\n",
        "    text_q = f\"✅ Predicted Build Quality: {pred_q}\"\n",
        "    text_p = f\"✅ Predicted Porosity: {pred_p}\"\n",
        "\n",
        "    return text_q, text_p, probs_q_dict, probs_p_dict, perf_text\n",
        "\n",
        "# ---------- Build Gradio UI ----------\n",
        "# create inputs dynamically (sliders)\n",
        "inputs = []\n",
        "for col in X.columns:\n",
        "    min_val, max_val = input_ranges[col]\n",
        "    # handle degenerate ranges\n",
        "    if min_val == max_val:\n",
        "        # fallback: use a Number input with default value\n",
        "        inputs.append(gr.Number(value=min_val, label=f\"{col} (constant value: {min_val})\"))\n",
        "    else:\n",
        "        step = (max_val - min_val) / 100.0\n",
        "        # If step is extremely small, set a reasonable minimum step\n",
        "        if step == 0:\n",
        "            step = 1.0\n",
        "        inputs.append(\n",
        "            gr.Slider(minimum=min_val, maximum=max_val, step=step, label=f\"{col} (range: {min_val:.4f} → {max_val:.4f})\")\n",
        "        )\n",
        "\n",
        "# outputs: predicted texts, probability labels, and a markdown performance summary\n",
        "outputs = [\n",
        "    gr.Textbox(label=\"Build Quality Prediction\"),\n",
        "    gr.Textbox(label=\"Porosity Prediction\"),\n",
        "    gr.Label(label=\"Build Quality Probabilities\"),\n",
        "    gr.Label(label=\"Porosity Probabilities\"),\n",
        "    gr.Markdown(label=\"Model Performance\"),\n",
        "]\n",
        "\n",
        "title = \"3D Printing — Build Quality & Porosity Prediction\"\n",
        "description = (\n",
        "    \"Enter printing parameters (use sliders) within dataset ranges to predict Build Quality and Porosity.\\n\\n\"\n",
        "    \"- Predictions come with class probabilities.\\n\"\n",
        "    \"- Models are Random Forests; scaler applied automatically.\\n\"\n",
        "    \"- To force retraining, delete the model files and re-run this script.\"\n",
        ")\n",
        "\n",
        "# Use Blocks to layout nicely\n",
        "with gr.Blocks(title=title) as demo:\n",
        "    gr.Markdown(f\"# {title}\")\n",
        "    gr.Markdown(description)\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### Input Parameters\")\n",
        "            input_components = [gr.update() for _ in inputs]  # placeholder list; we'll actually use `inputs` directly below\n",
        "            # place inputs\n",
        "            input_elems = []\n",
        "            for comp in inputs:\n",
        "                input_elems.append(comp)\n",
        "            submit_btn = gr.Button(\"Predict\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            gr.Markdown(\"### Predictions\")\n",
        "            out_q = outputs[0]\n",
        "            out_p = outputs[1]\n",
        "            out_q_comp = gr.Textbox(label=\"Build Quality Prediction\", interactive=False)\n",
        "            out_p_comp = gr.Textbox(label=\"Porosity Prediction\", interactive=False)\n",
        "            probs_q_comp = gr.Label(label=\"Build Quality Probabilities\")\n",
        "            probs_p_comp = gr.Label(label=\"Porosity Probabilities\")\n",
        "            perf_comp = gr.Markdown(perf_text)\n",
        "\n",
        "    # Wire up button -> function\n",
        "    # Gradio needs the actual input components (the objects in `inputs`)\n",
        "    submit_btn.click(\n",
        "        fn=predict_properties,\n",
        "        inputs=input_elems,\n",
        "        outputs=[out_q_comp, out_p_comp, probs_q_comp, probs_p_comp, perf_comp]\n",
        "    )\n",
        "\n",
        "# Launch: share=True gives public link (useful in Colab). Set server_port or server_name if running remotely.\n",
        "demo.launch(share=True)\n"
      ]
    }
  ]
}